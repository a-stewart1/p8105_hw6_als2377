---
title: "Homework 5"
author: Allison Stewart
output: github_document
---

This is my solution for Homework 5. 

```{r setup, include = FALSE}
library(tidyverse)
library(purrr)
library(ggplot2)
library(dplyr)
library(stringr)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6, 
  fig.asp = 0.6, 
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis", 
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1 

Read in homicide data. 

```{r}
homicide_df = 
  read_csv("homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")

aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Single Prop Test 

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Iteration 

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2

Read in data and iterate over file names.  

```{r}
path_df = 
  tibble(
    path = list.files("data"),
  ) %>% 
  mutate(
    path = str_c("data/", path),
    data = map(path, read_csv)) %>% 
  unnest() %>% 
  mutate(
    path = str_remove_all(path, ".csv"), 
    path = str_remove_all(path, "data/"), 
    path = str_replace_all(path, "con", "control"), 
    path = str_replace_all(path, "exp", "experiment")) %>% 
  separate(path, into = c("control_arm", "subject_id")) 
```

Make a spaghetti plot. 

```{r}
path_df %>% 
  pivot_longer(week_1:week_8, names_to = "week", values_to = "obs") %>% 
  mutate(
    week = str_remove_all(week, "week_")) %>%
  mutate(week = as.numeric(week)) %>% 
  ggplot(aes(x = week, y = obs, group = subject_id, color = subject_id)) + 
  geom_line() + facet_grid(.~control_arm) + 
  labs(
    title = "Observations Over Time by Control Arm", 
    x = "Week", 
    y = "Observation"
  )
```

Looking at this plot of "Observations Over Time by Control Arm", we can see an overall trend of increasing values over time for all study participants in the experimental group. In contrast, the observations for the participants of the control group vary over time but the values remain relatively stable in terms of the beginning and ending values over the study period. 

## Problem 3 

Set up simulation. 

```{r}
sample = function(n = 30, mu = 0, sigma = 5) {
  samp_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)) 
  
  samp_data %>% 
    summarize(
      mu = mean(x),
      sigma = sd(x))
  
  samp_data %>%
    t.test() %>%
    broom::tidy()

}

```

Test Function 

```{r}
samp_results = 
  rerun(5000, sample(30, 0, 5)) %>% 
  bind_rows()
```

Set up simulation. 

```{r}
sample = function(n = 30, mu = 0, sigma = 5) {
  samp_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)) 
  
  samp_data %>% 
    summarize(
      mu = mean(x),
      sigma = sd(x))
  
  samp_data %>%
    t.test() %>%
    broom::tidy()

}

```

Test Function 

```{r}
samp_results = 
  rerun(5000, sample(30, 0, 5)) %>% 
  bind_rows()
```

Hypothesis testing

```{r}
mu =
  list(
    "mu_0" = 0,
    "mu_1" = 1,
    "mu_2" = 2,
    "mu_3" = 3,
    "mu_4" = 4,
    "mu_5" = 5,
    "mu_6" = 6
    )

output = vector("list", length = 7)

for (i in 1:7) {
  output[[i]] = rerun(5000, sample(mu = mu[[i]])) %>% 
    bind_rows() 
}
```

Set up data for plotting

```{r}
plot_data =
  bind_rows(output, .id = "mu") %>% 
  select(mu, estimate, p.value) %>% 
  mutate(
    test_results = case_when(
      p.value < .05 ~ "reject",
      p.value >= .05 ~ "fail to reject"
      )) %>% 
  mutate(
    mu = recode(mu, "1" = "0", "2" = "1", "3" = "2", "4" = "3", "5" = "4", "6" = "5", "7" = "6")) %>% 
  mutate(mu = as.numeric(mu)) 
```

Plot proportion of times null is rejected 

```{r}
plot_data %>% 
  group_by(mu) %>% 
  mutate(
    power = sum(test_results == "reject") / 5000
  ) %>% 
  ggplot(aes(x = mu, y = power)) + geom_point() + labs(
    title = "Proportion of times the null is rejected", 
    x = "True Value of Mu", 
    y = "Power"
  )
```

This plots shows that there is a positive association between effect size and power. As effect size increases, power increases. 

Plot avg estimate of Mu by true Mu  

```{r}
plot_1 = 
plot_data %>% 
  group_by(mu) %>% 
  mutate(
    mean_estimate = mean(estimate)) %>% 
  ggplot(aes(x = mu, y = mean_estimate)) + geom_point() + labs(
    title = "Avg Est. of Mu by True Mu", 
    x = "True Mu", 
    y = "Average Estimate of Mu"
  )

plot_2 = 
  plot_data %>% 
  filter(test_results == "reject") %>% 
  group_by(mu) %>% 
  mutate(
    mean_estimate = mean(estimate)) %>% 
  ggplot(aes(x = mu, y = mean_estimate)) + geom_point() + labs(
    title = "Avg Est. of Mu, Null is Rejected", 
    x = "True Mu",
    y = "Average Estimate of Mu"
  )
  
plot_1 + plot_2

```

The sample average of mu across the tests for which the null is rejected is approximately equal to the true value of mu. There is a large enough sample size for the hypothesis tests to detect an effect, even though the effect is small. 