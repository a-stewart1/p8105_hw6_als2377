---
title: "Homework 5"
author: Allison Stewart
output: github_document
---

This is my solution for Homework 6. 

```{r setup, include = FALSE}
library(tidyverse)
library(purrr)
library(ggplot2)
library(dplyr)
library(stringr)
library(modelr)
library(mgcv)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6, 
  fig.asp = 0.6, 
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis", 
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1 

```{r}
homicide_df = 
  read_csv("homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors.

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

Run glm for each of the cities. 

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI")) 
```

Create a plot that shows estimated ORs and CIs for each city. 

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

# Problem 2 

Import and clean data. 

```{r}
baby_df = 
  read_csv("birthweight.csv") %>%
  mutate(
    babysex = as.factor(babysex), 
    frace = as.factor(frace), 
    mrace = as.factor(mrace)) 

summarize(baby_df, count = sum(is.na(baby_df)))
```

Propose a regression model for birthweight. 

```{r}
model_fit = lm(bwt ~ gaweeks +  blength + delwt + smoken, data = baby_df) 

model_fit %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  mutate(term = str_replace(term, "\\(Intercept\\)","intercept")) %>% 
  knitr::kable(digits = 3)
```

Based on hypothesized variables that influenced babyweight, I included the following variables in a linear regression model: mother's weight at delivery (delwt), gestational age in weeks (gaweeks), baby's length at birth (blength), and average number cigarettes smoked per day during pregnancy (smoken). The following plot shows the residuals of the model plotted against the fitted values. 

```{r}
baby_df %>% 
  add_residuals(model_fit) %>% 
  add_predictions(model_fit) %>% 
  select(resid, pred, delwt, gaweeks, smoken, blength) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.5) + 
  labs(
    title = "Residuals vs. Fitted Predictions", 
    x = "Fitted Prediction", 
    y = "Residuals"
  )
```

Compare the model to two others in terms of cross-validation prediction error. 

```{r}
fit1 = model_fit 
  
fit2 = lm(bwt ~ gaweeks + blength, data = baby_df) 

fit3 = lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex, data = baby_df)

baby_df %>% 
  gather_predictions(fit1, fit2, fit3) %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = blength, y = bwt)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red") + 
  facet_grid(~model)
```

```{r}
cv_df =
  crossv_mc(baby_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    fit1 = map(train, ~lm(bwt ~ gaweeks +  blength + delwt + smoken, data = .x)),
    fit2 = map(train, ~lm(bwt ~ gaweeks + blength, data = .x)),
    fit3 = map(train, ~gam(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex, data = as_tibble(.x)))) %>% 
  mutate(
    rmse_1 = map2_dbl(fit1, test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(fit2, test, ~rmse(model = .x, data = .y)),
    rmse_3 = map2_dbl(fit3, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() + 
  labs(
    title = "Comparing Model Fit by Root Means Square Errors (RMSE)", 
    x = "Model", 
    y = "RMSE"
  )
```

The plotted Root Means Square Errors (RMSE) for each model indicates that Model 3, the linear model containing head circumference, length, sex, and all interactions between the three variables produces the best fit. The significantly lower RMSE values of this model indicates a better fit. Models 1 and 2 produce fairly similar RMSE distributions and are worse in predictive accuracy as compared to Model 3. 

# Problem 3

Download 2017 Central Park weather data.  

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Set up bootstrapping.  

```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps = 
  tibble(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

```

Conduct analysis using bootstrapping. 

```{r}
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(.x = strap_sample, ~lm(tmax ~ tmin, data = .x)), 
    results = map(models, broom::tidy)) %>% 
  unnest(results) %>% 
  select(strap_number, term, estimate) %>% 
  mutate(
    term = str_replace(term, "\\(Intercept\\)", "intercept")) %>% 
 pivot_wider(
    names_from = "term", 
    values_from = "estimate"
  ) %>% 
  mutate(
    log = log(intercept * tmin)) 

bootstrap_results2 = 
  boot_straps %>% 
  mutate(
    models = map(.x = strap_sample, ~lm(tmax ~ tmin, data = .x )), 
    results = map(models, broom::glance)) %>% 
  unnest(results) %>% 
  select(strap_number, adj.r.squared)
```

Plot the distribution of the estimates. 

```{r}
plot1 = 
bootstrap_results2 %>% 
  ggplot(aes(x = adj.r.squared)) + geom_density() + 
  labs(
    title = "Distribution of Adjusted R-Squared", 
    x = "Adjusted R-Squared", 
    y = "Density"
  )

plot2 = bootstrap_results %>% 
  ggplot(aes(x = log)) + geom_density() + 
  labs(
    title = "Distribution of Log Estimate", 
    x = "Log Estimate",  
    y = "Density"
  )

plot1 + plot2 
```

The distribution of adjusted r-squared and log estimates both appear to be relatively symmetrical and normally distributed. The distribution of adjusted r-square estimates has a mean around 0.91, with a 95% confidence interval of 0.89-0.93, and the distribution of log estimates has a mean around 2.02, with a 95% confidence interval of 1.96-2.06.  

```{r}
#CI log 
bootstrap_results %>% 
  summarize(
    ci_lower = quantile(log, 0.025), 
    ci_upper = quantile(log, 0.975)) %>% 
  knitr::kable()

#CI adjusted r-squared
bootstrap_results2 %>% 
   summarize(
    ci_lower = quantile(adj.r.squared, 0.025), 
    ci_upper = quantile(adj.r.squared, 0.975)) %>% 
  knitr::kable()
```


